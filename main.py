import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import numpy as np
from datetime import datetime
from collections import Counter
import networkx as nx
from analyse_titre import (
    nettoyer_titres,
    vectoriser_titres,
    creer_clusters,
    mots_cles_par_cluster,
    appliquer_lda,
    calculer_entropie,
    entrainer_model,
    plot_mots_frequents,
    nettoyer
)



# Configuration de la page
st.set_page_config(
    page_title="Statistiques GLPI",
    layout="wide",
    page_icon="üìä",
    initial_sidebar_state="expanded"
)

# Styles CSS personnalis√©s
st.markdown("""
    <style> 
        .main { background-color: #f8f9fa; }
        .stMetric { border-radius: 10px; padding: 15px; background-color: white; box-shadow: 0 4px 6px rgba(0,0,0,0.1); }
        .stMetric label { font-size: 1rem !important; font-weight: 600 !important; color: #4a4a4a !important; }
        .stMetric div { font-size: 1.5rem !important; font-weight: 700 !important; color: #2c3e50 !important; }
        .stPlotlyChart { border-radius: 10px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); background-color: white; padding: 15px; }
        .stDataFrame { border-radius: 10px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); }
        .stExpander { border-radius: 10px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); background-color: white; padding: 15px; }
        #.stAlert{ background-color: #f9f0a3;}
        .css-1aumxhk { background-color: #2c3e50; color: white; }
        h1 { color: #2c3e50; border-bottom: 2px solid #066c5d; padding-bottom: 10px; }
        h2 { color: #2c3e50; }
        .stMarkdown { background-color: white; border-radius: 10px; padding: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); }
    </style>
""", unsafe_allow_html=True)

# Titre principal
st.title("üìä Tableau de Bord GLPI")
st.markdown("""
    <div style="background-color:#066c5d;padding:15px;border-radius:10px;color:white;margin-bottom:20px;">
        <h3 style="margin:0;color:white;">Un aper√ßu interactif et visuel des tickets g√©n√©r√©s dans GLPI</h3>
    </div>
""", unsafe_allow_html=True)

# Import du fichier de donn√©es
with st.expander("üì§ Importer des donn√©es", expanded=True):
    fichier_importe = st.file_uploader(
        "S√©lectionnez un fichier CSV ou Excel export√© depuis GLPI",
        type=["csv", "xlsx"],
        help="Le fichier doit contenir les colonnes standards de GLPI"
    )

# Barre lat√©rale : Logo, navigation, infos, options, pied de page
with st.sidebar:

    # Infos du fichier import√©
    st.markdown("## ‚ÑπÔ∏è Informations du fichier")
    if fichier_importe:
        st.markdown(f"**Nom du fichier :** `{fichier_importe.name}`")
        st.markdown(f"**Taille :** {round(fichier_importe.size / 1024, 2)} ko")
        st.markdown(f"**Type :** {fichier_importe.type}")
    else:
        st.markdown("Aucun fichier charg√©.")

    # Acces rapide
    st.markdown("""
    <div style='padding: 5px; border-radius: 10px;'>
    <h4 style='margin-bottom: 10px;'>üìç Acc√®s rapide</h4>
    <ul style='list-style: none; padding-left: 0; font-size: 15px;'>
    <li><a href="#kpi"> KPIs</a></li>
    <li><a href="#visualisation"> Visualisation</a></li>
    <li><a href="#analysesdetaillees"> Analyses d√©taill√©es</a></li>
    <li><a href="#ticketsinactifs"> Tickets inactifs</a></li>
    <li><a href="#graphedeconcurrence"> Graphe de cooccurrence</a></li>
    <li><a href="#analyseintelligente"> Analyse intelligente des titres</a></li>
    </ul>
    </div>
    """, unsafe_allow_html=True)




if fichier_importe:
    try:
        # Lecture du fichier selon son type
        if fichier_importe.name.endswith('.csv'):
            donnees = pd.read_csv( fichier_importe, encoding='utf-8-sig', sep=';', dayfirst=True)
        else:
            donnees = pd.read_excel(fichier_importe)
        
        # Nettoyage
        donnees = donnees.dropna(how='all')
        st.success("‚úÖ Donn√©es charg√©es avec succ√®s‚ÄØ!")
        with st.sidebar: 
            donnees["Derni√®re modification"] = pd.to_datetime(donnees["Derni√®re modification"], errors='coerce',dayfirst=True)
            derniere_date = donnees["Derni√®re modification"].max()
            st.markdown(f"**Ce fichier traite les tickets jusqu'au :** {derniere_date.strftime('%Y-%m-%d %H:%M:%S')}")

            # Pied de page
            st.markdown("""
            <small>D√©velopp√© par Kenza</small><br>
            <small>Version 1.0.0</small>
            """, unsafe_allow_html=True)

        # KPIs
        st.markdown('<a name="kpi"></a>', unsafe_allow_html=True)
        st.subheader("üìà Indicateurs cl√©s")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric(
                label="üéüÔ∏è Nombre total de tickets",
                value=len(donnees),
                help="Total des tickets dans le fichier import√©"
            )
        with col2:
            if "Plugins - Champs Sup - Etablissement" in donnees.columns:
                services_count = donnees["Plugins - Champs Sup - Etablissement"].nunique()
            else:
                services_count = "N/A"
            st.metric(
                label="üë• Nombre de services",
                value=services_count,
                help="Nombre de services g√©n√©rant des tickets"
            )
        with col3:
            if "Priorit√©" in donnees.columns:
                priorites_count = donnees["Priorit√©"].nunique()
            else:
                priorites_count = "N/A"
            st.metric(
                label="üî• Types de priorit√©",
                value=priorites_count,
                help="Nombre de niveaux de priorit√© diff√©rents"  
            )
        with col4:
            tickets_ouverts = donnees[donnees["Statut"] == "Nouveau"]
            st.metric(
                label="üì¨ Nouveaux tickets",
                value=len(tickets_ouverts),
                help="Nombre de tickets non ouverts"  
            )

        st.markdown("---")
        st.subheader("üîç Exploration des donn√©es")
        with st.expander("üìã Aper√ßu des donn√©es brutes", expanded=False):
            st.dataframe(donnees.style.background_gradient(cmap='Blues'), use_container_width=True)
            csv_export = donnees.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üì• T√©l√©charger les donn√©es",
                data=csv_export,
                file_name='glpi_donnees_filtrees.csv',
                mime='text/csv',
                help="T√©l√©chargez les donn√©es visibles"
            )
        
        # ------------------------------
        # üìä Visualisations interactives
        # ------------------------------
        # Cette section propose 3 visualisations majeures √† partir des donn√©es :
        # 1. Par service (r√©partition des tickets)
        # 2. Par priorit√© (niveaux d'urgence)
        # 3. Par chronologie (tendance temporelle + activit√© horaire)

        st.subheader("üìä Visualisations")
        st.markdown('<a name="visualisation"></a>', unsafe_allow_html=True)
        # Onglets de navigation th√©matique
        tab_service, tab_prio = st.tabs(["üìÇ Par service", "üéØ Par priorit√©"])

        # -------------------------------------------
        # üè¢ Onglet 1 : Visualisation par service
        # -------------------------------------------
        with tab_service:
            st.markdown("""
            ### üè¢ Analyse par service
            Ce graphique permet de visualiser quels services g√©n√®rent le plus de tickets.
            Cela aide √† identifier les unit√©s les plus sollicit√©es.
            """)
            if "Plugins - Champs Sup - Etablissement" in donnees.columns:
                df_service = donnees["Plugins - Champs Sup - Etablissement"].value_counts().reset_index()
                df_service.columns = ["Service", "Tickets"]

                # Deux colonnes : graphique + statistiques cl√©s
                c1, c2 = st.columns([3, 1])

                with c1:
                    fig_service = px.bar(
                        df_service.head(10),
                        x="Tickets", y="Service", orientation='h',
                        title="Top‚ÄØ10 des services par nombre de tickets",
                        color="Service", template="plotly_white", height=600
                    )
                    st.plotly_chart(fig_service, use_container_width=True)

                with c2:
                    st.metric(
                        label="üèÜ Service le plus actif",
                        value=df_service.iloc[0]["Service"],
                        delta=f"{df_service.iloc[0]['Tickets']} tickets"
                    )
                    st.metric(
                        label="üìä % du total",
                        value=f"{(df_service.iloc[0]['Tickets']/len(donnees)*100):.1f}‚ÄØ%"
                    )
            else:
                st.warning("La colonne 'Plugins - Champs Sup - Etablissement' est absente.")

        # -------------------------------------------
        # üéØ Onglet 2 : Visualisation par priorit√©
        # -------------------------------------------
        with tab_prio:
            st.markdown("""
            ### üéØ Analyse par priorit√©
            Ici, on visualise la r√©partition des tickets selon leur degr√© d'urgence ou de criticit√© (basse, moyenne, haute).
            Cela permet de comprendre si l'organisation traite majoritairement des incidents critiques ou des demandes mineures.
            """)
            if "Priorit√©" in donnees.columns:
                df_prio = donnees["Priorit√©"].value_counts().reset_index()
                df_prio.columns = ["Priorit√©", "Tickets"]

                c1, c2 = st.columns([3, 1])

                with c1:
                    # Diagramme circulaire des priorit√©s
                    fig_prio = px.pie(
                        df_prio, names="Priorit√©", values="Tickets",
                        title="R√©partition des tickets par priorit√©",
                        hole=0.4,
                        color_discrete_sequence=px.colors.sequential.RdBu
                    )
                    st.plotly_chart(fig_prio, use_container_width=True)

                with c2:
                    st.metric(
                        label="‚ö†Ô∏è Priorit√© la plus fr√©quente",
                        value=df_prio.iloc[0]["Priorit√©"],
                        delta=f"{df_prio.iloc[0]['Tickets']} tickets"
                    )
                    # Petit graphique compl√©mentaire en barres
                    fig_prio_bar = px.bar(
                        df_prio, x="Priorit√©", y="Tickets",
                        color="Priorit√©", height=220
                    )
                    st.plotly_chart(fig_prio_bar, use_container_width=True)
            else:
                st.warning("La colonne 'Priorit√©' est absente.")
    
        st.markdown("---")

        # -----------------------------
        # üìå ANALYSES D√âTAILL√âES
        # -----------------------------
        # Cette section approfondit l'analyse des tickets via plusieurs perspectives :
        # üîπ Statuts et priorit√©s (tableau crois√© dynamique)
        # üìÜ Activit√© temporelle : mois, jour, heure
        # üë§ Analyse des acteurs : demandeurs, techniciens
        # üóÇÔ∏è R√©partition par cat√©gories

        st.subheader("üìå Analyses d√©taill√©es")
        st.markdown('<a name="analysesdetaillees"></a>', unsafe_allow_html=True)
 
        # Onglets principaux

        tab_statut,tab_mois, tab_jour, tab_heure = st.tabs([
            "üîπ Statuts par priorit√©",
            "üìÜ Activit√© par mois",
            "üìÖ Activit√© par jour",
            "üïí Activit√© par heure"
        ])

        # -------------------------------
        # üîπ Statuts par priorit√©
        # -------------------------------
        with tab_statut:
            st.markdown("""
            Ce tableau crois√© dynamique montre comment les statuts des tickets (nouveau, r√©solu, en attente...) se r√©partissent selon leur priorit√© (haute, basse...).
            Cela permet de d√©tecter, par exemple, si les tickets urgents restent souvent non trait√©s.
            """)
            if "Statut" in donnees.columns and "Priorit√©" in donnees.columns:
                tab_stat = pd.crosstab(donnees["Priorit√©"], donnees["Statut"])
                st.dataframe(tab_stat)
                fig_statut = px.bar(
                    tab_stat,
                    barmode='group',
                    title="üìä R√©partition des statuts par priorit√©"
                )
                st.plotly_chart(fig_statut, use_container_width=True)
            else:
                st.warning("Colonnes 'Statut' ou 'Priorit√©' manquantes.")

        # -------------------------------
        # üìÜ Activit√© par mois
        # -------------------------------
        with tab_mois:
            st.markdown("""
            Cette double visualisation met en √©vidence des p√©riodes de forte ou faible activit√© (vacances, incidents, etc). Elle permet de voir :
            - l'√©volution mensuelle des tickets (barre + courbe)
            - la moyenne mobile sur 7 jours (tendance liss√©e)
            """)
            if "Derni√®re modification" in donnees.columns:
                try:
                    donnees["Mois"] = pd.to_datetime(donnees["Derni√®re modification"]).dt.to_period("M").astype(str)
                    mensuels = donnees["Mois"].value_counts().sort_index()
                    c1, c2 = st.columns(2)
                    with c1:
                        fig_mensuel_line = px.line(
                            mensuels, title="√âvolution mensuelle des tickets",
                            labels={'value': 'Tickets', 'index': 'Mois'}, markers=True
                        )
                        st.plotly_chart(fig_mensuel_line, use_container_width=True)
                    with c2:
                        fig_mensuel_bar = px.bar(
                            mensuels, title="R√©partition mensuelle des tickets",
                            labels={'value': 'Tickets', 'index': 'Mois'},
                            color=mensuels.index
                        )
                        st.plotly_chart(fig_mensuel_bar, use_container_width=True)                  
                except:
                    st.warning("Analyse mensuelle impossible avec les dates.")
            else:
                st.warning("La colonne 'Derni√®re modification' est absente.")

        # -------------------------------
        # üìÖ Activit√© par jour + heure
        # -------------------------------
        with tab_jour:
            st.markdown("""
            Cette heatmap repr√©sente l'activit√© des tickets selon l'heure et la date.
            Elle est utile pour rep√©rer les horaires les plus intenses ou les jours √† forte charge.
            """)

            if "Derni√®re modification" in donnees.columns:
                # Conversion de la colonne en datetime
                donnees["Derni√®re modification"] = pd.to_datetime(donnees["Derni√®re modification"], dayfirst=True)

                # Cr√©ation des colonnes "Date" et "Heure"
                donnees["Date"] = donnees["Derni√®re modification"].dt.date.astype(str)
                donnees["Heure"] = donnees["Derni√®re modification"].dt.hour

                # Tickets par date (compte)
                tickets_pour_date = donnees["Date"].value_counts().sort_index()

                # üìä Affichage c√¥te √† c√¥te : tableau + graphique
                col1, col2 = st.columns([1, 3])  # 1/4 pour le tableau, 3/4 pour le graphique

                with col1:
                    st.subheader("R√©sum√© quotidien")
                    st.dataframe(tickets_pour_date.rename("Nombre de tickets"))

                with col2:
                    fig2 = px.line(
                        tickets_pour_date,
                        title="√âvolution du nombre de tickets par jour",
                        labels={'value': 'Tickets', 'index': 'Date'},
                        template="plotly_white"
                    )
                    fig2.update_traces(line_color='#3498db', line_width=3)
                    st.plotly_chart(fig2, use_container_width=True, key="lineplot1")

                # üî• Heatmap : activit√© par heure et jour
                heatmap_data = donnees.pivot_table(index="Heure", columns="Date", aggfunc='size', fill_value=0)

                fig1 = px.imshow(
                    heatmap_data,
                    labels=dict(x="Date", y="Heure", color="Nombre de tickets"),
                    aspect="auto",
                    title="Heatmap du nombre de tickets par jour et heure"
                )
                st.plotly_chart(fig1, use_container_width=True, key="heatmap1")

            else: 
                st.warning("La colonne 'Derni√®re modification' n'existe pas dans ce fichier.")


        # -------------------------------
        # üïí Activit√© par heure uniquement
        # -------------------------------
        with tab_heure:
            st.markdown("""
            Ce graphique montre les heures o√π le plus de tickets sont modifi√©s.
            """)
            if "Derni√®re modification" in donnees.columns:
                donnees["Heure"] = pd.to_datetime(donnees["Derni√®re modification"], errors='coerce',dayfirst=True).dt.hour
                heure_count = donnees["Heure"].value_counts().sort_index()
                st.bar_chart(heure_count)
            else:
                st.warning("Colonne 'Derni√®re modification' absente.")



        tab_tech,tab_demandeur, tab_categorie = st.tabs(["üë®‚Äçüíª Par technicien", "üë§ Tickets par demandeur", "üóÇÔ∏è Par cat√©gorie"])

        # -------------------------------
        # üë®‚Äçüíª Par technicien
        # -------------------------------
        with tab_tech:
            st.markdown("""
            Ce graphique affiche les techniciens les plus sollicit√©s selon le nombre de tickets qui leur sont assign√©s.
            Cela permet d'√©valuer la charge de travail de chaque intervenant technique.
            """)
            if "Attribu√© √† - Technicien" in donnees.columns:
                donnees["Attribu√© √† - Technicien"] = donnees["Attribu√© √† - Technicien"].fillna("Non assign√©")
                df_tech = donnees["Attribu√© √† - Technicien"].value_counts().reset_index()
                df_tech.columns = ["Technicien", "Tickets"]
                fig_tech = px.bar(
                    df_tech.head(20),
                    x="Tickets", y="Technicien", orientation='h',
                    title="Top‚ÄØ20 des techniciens par nombre de tickets assign√©s",
                    color="Technicien", height=600
                )
                st.plotly_chart(fig_tech, use_container_width=True)
            else:
                st.warning("La colonne 'Attribu√© √† - Technicien' est absente.")

        # -------------------------------
        # üìÖ Par demandeur
        # -------------------------------
        with tab_demandeur:
            st.markdown("""
            Cette vue classe les demandeurs (utilisateurs finaux) selon le nombre de tickets cr√©√©s.
            On peut y identifier les services ou personnes les plus actives.
            """)
            if "Demandeur - Demandeur" in donnees.columns:
                donnees["Demandeur - Demandeur"] = donnees["Demandeur - Demandeur"].fillna("Non assign√©").replace("", "Non assign√©")
                df_demandeur = donnees["Demandeur - Demandeur"].value_counts().reset_index()
                df_demandeur.columns = ["Demandeur", "Tickets"]
                fig_demandeur = px.bar(
                    df_demandeur.head(20),
                    x="Tickets", y="Demandeur", orientation='h',
                    title="Top 20 des demandeurs de tickets",
                    color="Demandeur", height=600
                )
                st.plotly_chart(fig_demandeur, use_container_width=True)
            else:
                st.warning("La colonne 'Demandeur - Demandeur' est absente.")

        # -------------------------------
        # üóÇÔ∏è Par cat√©gorie principale
        # -------------------------------
        with tab_categorie:
            st.markdown("""
            Ici, les tickets sont regroup√©s selon les grandes cat√©gories (ex : Logiciels, R√©seau...).
            Cela facilite la priorisation des interventions et la compr√©hension des domaines les plus sensibles.
            """)
            if "Cat√©gorie" in donnees.columns:
                donnees[["Cat√©gorie principale", "Sous‚Äëcat√©gorie"]] = donnees["Cat√©gorie"].str.split(">", n=1, expand=True)
                donnees["Cat√©gorie principale"] = donnees["Cat√©gorie principale"].str.strip()
                donnees["Sous‚Äëcat√©gorie"] = donnees["Sous‚Äëcat√©gorie"].str.strip()

                df_cat = donnees["Cat√©gorie principale"].value_counts().reset_index()
                df_cat.columns = ["Cat√©gorie", "Tickets"]
                fig_treemap = px.treemap(
                    df_cat,
                    path=['Cat√©gorie'],
                    values='Tickets',
                    title="R√©partition par cat√©gorie principale"
                )
                st.plotly_chart(fig_treemap, use_container_width=True)

                categorie_sel = st.selectbox(
                    "S√©lectionnez une cat√©gorie principale pour voir ses sous‚Äëcat√©gories :",
                    donnees["Cat√©gorie principale"].dropna().unique()
                )
                if categorie_sel:
                    df_sub = donnees[donnees["Cat√©gorie principale"]==categorie_sel]["Sous‚Äëcat√©gorie"].value_counts().reset_index()
                    df_sub.columns = ["Sous‚Äëcat√©gorie", "Tickets"]
                    fig_sub = px.bar(
                        df_sub, x="Tickets", y="Sous‚Äëcat√©gorie",
                        orientation='h',
                        title=f"Sous‚Äëcat√©gories dans : {categorie_sel}",
                        height=500
                    )
                    st.plotly_chart(fig_sub, use_container_width=True)
            else:
                st.warning("La colonne 'Cat√©gorie' est absente.")
                
        
        st.markdown("---")
        # -----------------------
        # üî¢ Tickets inactifs depuis X jours
        # -----------------------
        st.subheader("‚è≥ Tickets inactifs")
        st.markdown('<a name="ticketsinactifs"></a>', unsafe_allow_html=True)

        jours_seuil = st.slider("Inactivit√© depuis (jours)", min_value=1, max_value=60, value=7)
        if "Derni√®re modification" in donnees.columns:
            donnees["Derni√®re modification"] = pd.to_datetime(donnees["Derni√®re modification"], errors="coerce",dayfirst=True)
            inactifs = donnees[donnees["Derni√®re modification"] < (pd.Timestamp.now() - pd.Timedelta(days=jours_seuil))]
            
            st.info(f"üéØ {len(inactifs)} tickets sont inactifs depuis plus de **{jours_seuil} jours**.")
            st.dataframe(inactifs[["ID", "Titre", "Statut", "Derni√®re modification"]].sort_values(by="Derni√®re modification"))
        else:
            st.warning("Colonne 'Derni√®re modification' absente.")
        st.markdown("---")


        # -----------------------
        # üî¢ Menu d√©roulant pour choisir la visualisation
        # -----------------------

        choix_visu = st.selectbox(
            "Choisissez la visualisation √† afficher :",
            ["üß† Mots fr√©quents (camembert)", "üåê Graphe de cooccurrence"]
        )

        # -----------------------
        # üß† Mots-cl√©s fr√©quents dans les tickets non r√©solus (Camembert)
        # -----------------------

        if choix_visu == "üß† Mots fr√©quents (camembert)":
            st.subheader("üß† Mots fr√©quents dans les tickets non r√©solus")

            if "Titre" in donnees.columns and "Statut" in donnees.columns:
                non_resolus = donnees[~donnees["Statut"].isin(["R√©solu", "Clos", "Ferm√©", "Termin√©"])]
                titres = non_resolus["Titre"].dropna().astype(str).apply(nettoyer)
                flat = [mot for liste in titres for mot in liste]
                freqs = Counter(flat).most_common(15)

                mots, valeurs = zip(*freqs)

                fig_donut = px.pie(
                    names=mots,
                    values=valeurs,
                    hole=0.4,
                    title="Distribution des mots les plus fr√©quents (tickets non r√©solus)",
                    color_discrete_sequence=px.colors.sequential.Plasma_r
                )
                st.plotly_chart(fig_donut, use_container_width=True)

                top_mots = ", ".join([f"'{m}'" for m in mots[:10]])

                st.success(
                    f"""
                    Les 10 mots les plus fr√©quents dans les titres des tickets non r√©solus sont : {top_mots}.  
                    Leur fr√©quence √©lev√©e sugg√®re qu‚Äôils repr√©sentent des th√©matiques r√©currentes dans les probl√®mes non trait√©s.  
                    """
                )

            else:
                st.warning("Colonnes 'Titre' ou 'Statut' manquantes.")

        # -----------------------
        # üåê Graphe de cooccurrence des mots-cl√©s
        # -----------------------

        elif choix_visu == "üåê Graphe de cooccurrence":
            st.subheader("üåê Graphe de cooccurrence des mots dans les titres")
            st.markdown('<a name="graphedeconcurrence"></a>', unsafe_allow_html=True)

            if "Titre" in donnees.columns:
                titres_clean = donnees["Titre"].dropna().astype(str).apply(nettoyer)

                # Calcul cooccurrences
                cooccurrence = Counter()
                for mots_titre in titres_clean:
                    mots_uniques = list(set(mots_titre))
                    for i in range(len(mots_uniques)):
                        for j in range(i + 1, len(mots_uniques)):
                            paire = tuple(sorted((mots_uniques[i], mots_uniques[j])))
                            cooccurrence[paire] += 1

                seuil = 3
                edges = [(a, b, {"weight": w}) for (a, b), w in cooccurrence.items() if w >= seuil]

                G = nx.Graph()
                G.add_edges_from(edges)

                if len(G.nodes) == 0:
                    st.info(f"Aucun lien de cooccurrence trouv√© avec un seuil >= {seuil}. Essayez de baisser le seuil.")
                else:
                    nb_mots = len(G.nodes)
                    nb_liens = len(G.edges)
                    centralite = nx.degree_centrality(G)
                    mot_central = max(centralite, key=centralite.get)
                    centralite_max = centralite[mot_central]
                    densite = nx.density(G)

                    pos = nx.spring_layout(G, k=0.5, seed=42)
                    plt.figure(figsize=(10, 8))
                    nx.draw(
                        G, pos,
                        with_labels=True,
                        node_size=[v * 1000 for v in centralite.values()],
                        node_color='#407fb2',
                        font_size=7,
                        edge_color='#0877d1',
                        width=[G[u][v]['weight'] * 0.2 for u, v in G.edges()]
                    )
                    st.pyplot(plt)
                    plt.clf()

                    # R√©sum√© chiffr√©
                    st.markdown(f"""
                    <table style="width:100%; border-collapse: collapse; border: 1px solid #ddd;">
                    <tr>
                        <td style="padding: 8px; border: 1px solid #ddd;">üß© <b>Nombre total de mots-cl√©s distincts analys√©s</b></td>
                        <td style="padding: 8px; border: 1px solid #ddd; text-align:center;"><b>{nb_mots}</b></td>
                    </tr>
                    <tr>
                        <td style="padding: 8px; border: 1px solid #ddd;">üîó <b>Nombre de relations fr√©quentes entre ces mots</b></td>
                        <td style="padding: 8px; border: 1px solid #ddd; text-align:center;"><b>{nb_liens}</b></td>
                    </tr>
                    <tr>
                        <td style="padding: 8px; border: 1px solid #ddd;">üìä <b>Densit√© du r√©seau de cooccurrence</b></td>
                        <td style="padding: 8px; border: 1px solid #ddd; text-align:center;"><b>{densite:.3f}</b></td>
                    </tr>
                    <tr>
                        <td style="padding: 8px; border: 1px solid #ddd;">‚≠ê <b>Mot-cl√© le plus central</b></td>
                        <td style="padding: 8px; border: 1px solid #ddd; text-align:center;"><b>'{mot_central}' (centralit√© = {centralite_max:.2f})</b></td>
                    </tr>
                    </table>
                    """, unsafe_allow_html=True)

                    # üü¢ Conclusion explicative
                    mots_connectes = sorted(list(G.nodes))[:5]
                    mots_connectes_str = ", ".join([f"'{m}'" for m in mots_connectes])

                    st.success(
                        f"""
                        Le r√©seau de cooccurrence met en √©vidence des liens fr√©quents entre des mots comme {mots_connectes_str}.  
                        Cela montre que ces termes apparaissent ensemble dans de nombreux titres, traduisant des probl√©matiques li√©es ou des tickets traitant de th√®mes communs.  
                        
                        Le mot **'{mot_central}'**, central dans ce graphe, semble jouer un r√¥le de pivot th√©matique. Il pourrait d√©signer une source fr√©quente de blocage ou un sujet transversal.

                        Une densit√© de **{densite:.3f}** sugg√®re un niveau de connectivit√© {'√©lev√©' if densite > 0.15 else 'mod√©r√©' if densite > 0.05 else 'faible'} : les sujets trait√©s dans les tickets sont donc {'fortement reli√©s entre eux' if densite > 0.15 else 'parfois li√©s' if densite > 0.05 else 'plut√¥t isol√©s'}.

                        üëâ Ces informations permettent d‚Äôidentifier rapidement les th√©matiques dominantes et leur interconnexion, pour mieux structurer les r√©solutions ou organiser les priorit√©s.
                        """
                    )

            else:
                st.warning("Colonne 'Titre' absente.")

        st.markdown("---")

        # --------------------------
        # üß† Analyse NLP des titres am√©lior√©e
        # --------------------------
        st.subheader("üß† Analyse intelligente des titres")
        st.markdown('<a name="analyseintelligente"></a>', unsafe_allow_html=True)

        if "Titre" in donnees.columns:
            titres_nettoyes = nettoyer_titres(donnees["Titre"])
            donnees_valides = donnees.loc[titres_nettoyes.index]
            X, vectoriseur = vectoriser_titres(titres_nettoyes)
            clusters, modele = creer_clusters(X)
            donnees_valides["Groupe de titres"] = clusters

            

            # üìà Mots fr√©quents
            st.markdown("### üìà Mots les plus fr√©quents")
            with st.expander("‚ÑπÔ∏è Explications d√©taill√©es sur le regroupement en groupes"):
                st.markdown("""
                Cette section g√©n√®re un graphique en barres (matplotlib) repr√©sentant les mots les plus fr√©quents dans les titres.  
                Avant l‚Äôanalyse, les titres ont √©t√© nettoy√©s √† l‚Äôaide d‚Äôune fonction qui :  
                - supprime les stopwords (mots tr√®s courants comme "le", "la", "de"),  
                - √©limine les chiffres, la ponctuation et les mots trop courts,  
                - homog√©n√©ise les mots pour √©viter les doublons inutiles.  

                Ce traitement permet de se concentrer sur les termes les plus significatifs et d‚Äô√©viter que des mots sans r√©elle valeur s√©mantique ne biaisent l‚Äôanalyse.
                """)

            fig_freq = plot_mots_frequents(titres_nettoyes)
            st.pyplot(fig_freq)

            # üîë Mots-cl√©s 
            st.markdown("### üîë Mots-cl√©s par groupe")
            with st.expander("‚ÑπÔ∏è Explications d√©taill√©es sur le regroupement en groupes"):
                st.markdown("""
                Dans cette section, on regroupe les titres dans des clusters et cela en se basant sur deux alogrithmes : 

                2. **Vectorisation TF-IDF**  
                Chaque titre est transform√© en un vecteur num√©rique repr√©sentant l'importance des mots pr√©sents dans ce titre par rapport √† tous les titres.  
                Cela permet de comparer facilement les titres entre eux.

                3. **Clustering (regroupement en groupes)**  
                Un algorithme (K-means) regroupe les titres en 6 clusters (groupes) selon leur similarit√© s√©mantique.  
                Par exemple, un cluster peut regrouper tous les titres parlant de probl√®mes d'imprimante, un autre ceux li√©s √† la connexion internet, etc.

                4. **Mots-cl√©s par groupe**  
                Pour chaque groupe, on extrait les 5 mots les plus caract√©ristiques, permettant de comprendre rapidement le th√®me de chaque cluster.
                """)
            mots_par_groupe = mots_cles_par_cluster(modele, vectoriseur)
            for i, mots in enumerate(mots_par_groupe):
                st.markdown(f"**Groupe {i}** : {' - '.join(mots)}")
            st.markdown("""
            _Ces mots sont les plus repr√©sentatifs de chaque groupe. Par exemple, si le groupe 0 affiche ¬´ connexion - r√©seau - wifi ¬ª, cela signifie que les titres de ce groupe parlent principalement de probl√®mes de connexion r√©seau._
            """)

            # üîç Exemples
            st.markdown("### üîç Aper√ßu dynamique des titres par groupe")
            groupe_choisi = st.selectbox("Choisir un groupe :", sorted(donnees_valides["Groupe de titres"].unique()))
            exemples = donnees_valides[donnees_valides["Groupe de titres"] == groupe_choisi]["Titre"].head(10)
            st.table(exemples.to_frame())
            st.markdown("""
            _Vous pouvez s√©lectionner un groupe pour voir quelques exemples de titres qui en font partie, afin de mieux comprendre le th√®me du groupe._
            """)

            # üìä R√©partition (bar + pie)
            distribution = donnees_valides["Groupe de titres"].value_counts().sort_index()
            col1, col2 = st.columns(2)

            with col1:
                st.markdown("#### üìä Nombre de titres par groupe")
                st.markdown("> Ce graphique montre combien de titres ont √©t√© automatiquement regroup√©s dans chaque groupe.")
                fig_bar, ax_bar = plt.subplots()
                sns.barplot(x=distribution.index, y=distribution.values, ax=ax_bar, palette="Set2")
                ax_bar.set_xlabel("Groupe")
                ax_bar.set_ylabel("Nombre de titres")
                st.pyplot(fig_bar)

            with col2:
                st.markdown("#### ü•ß R√©partition en pourcentage")
                st.markdown("> Le camembert illustre la proportion relative de chaque groupe dans l‚Äôensemble des tickets.")
                fig_pie, ax_pie = plt.subplots()
                ax_pie.pie(distribution, labels=[f"Groupe {i}" for i in distribution.index],
                        autopct="%1.1f%%", startangle=90)
                ax_pie.axis("equal")
                st.pyplot(fig_pie)

            # üßÆ Entropie
            st.markdown("### üßÆ Diversit√© s√©mantique")
            st.markdown("""
            > L'entropie est un indicateur qui permet d'√©valuer √† quel point les titres sont **r√©partis de mani√®re √©quilibr√©e entre les groupes**.  
            > Plus l'entropie est √©lev√©e, plus la diversit√© th√©matique est grande.
            """)

            # Calculs
            entropie_val = calculer_entropie(donnees_valides)
            max_entropie = np.log(6)  # log du nombre de groupes
            pourcentage = (entropie_val / max_entropie) * 100

            # Affichage
            st.info(f"Entropie mesur√©e : **{entropie_val:.2f}** / **{max_entropie:.2f}** (soit **{pourcentage:.0f}%** de diversit√© possible)")

            # Analyse automatique
            if pourcentage >= 70:
                st.success("‚úîÔ∏è Les titres sont bien r√©partis entre les groupes. Cela indique une **bonne diversit√© th√©matique**.")
            elif 40 <= pourcentage < 70:
                st.warning("‚ö†Ô∏è Les titres sont partiellement concentr√©s. Certains groupes dominent l√©g√®rement.")
            else:
                st.error("‚ùó Faible diversit√© : la majorit√© des titres semblent concerner **un sujet principal**.")

                # Trouver le groupe dominant
                groupe_majoritaire = donnees_valides["Groupe de titres"].value_counts().idxmax()
                mots_dominants = mots_par_groupe[groupe_majoritaire][:5]
                st.markdown(f"""
                _Dans notre cas, le **groupe {groupe_majoritaire}** est largement dominant._
                
                Ce groupe est associ√© aux mots-cl√©s suivants : **{'**, **'.join(mots_dominants)}**  
                üëâ Cela sugg√®re que les titres parlent principalement de : **{' '.join(mots_dominants)}**
                """)

            # Info p√©dagogique
            st.markdown(f"""
            _√Ä titre de r√©f√©rence :_
            - Une entropie proche de **{max_entropie:.2f}** signifie une excellente r√©partition (100% diversit√©)
            - Une entropie proche de **0** signifie une tr√®s forte concentration sur un seul th√®me
            """)


            # ü§ñ Mod√®le
            st.markdown("### ü§ñ Mod√®le de pr√©diction")
            with st.expander("üß† En savoir plus : comment fonctionne ce mod√®le ?"):
                st.markdown("""
                    > Un mod√®le de machine learning (ici une **r√©gression logistique**) a √©t√© entra√Æn√© pour apprendre √† **reconna√Ætre automatiquement √† quel groupe appartient un titre**, uniquement √† partir des mots qu'il contient.
                    >
                    > Ce mod√®le est utile si tu veux **classer automatiquement de nouveaux tickets** dans les bons th√®mes sans intervention humaine.

                    La **r√©gression logistique** est un algorithme simple mais puissant qui apprend √† **associer des mots √† des classes**.

                    Voici les √©tapes :
                    1. Chaque titre est converti en vecteur de mots (gr√¢ce √† la vectorisation)
                    2. Le mod√®le apprend sur ces vecteurs et leurs groupes r√©els
                    3. Ensuite, pour un nouveau titre, il **calcule la probabilit√©** qu'il appartienne √† chaque groupe
                    4. Il choisit celui avec la plus forte probabilit√©

                    C‚Äôest un algorithme largement utilis√© pour les t√¢ches de **classification automatique de texte**, car :
                    - il est rapide √† entra√Æner
                    - il fonctionne bien sur des donn√©es peu complexes
                    - il peut donner une **probabilit√© pour chaque classe**, ce qui est utile pour mesurer la confiance du mod√®le
                """)
          

            # Entra√Ænement + score + matrice
            score, matrice = entrainer_model(X, donnees_valides["Groupe de titres"])
            st.success(f"üéØ Pr√©cision du mod√®le : **{score:.2%}**")

            # Explication en langage simple
            st.markdown(f"""
            _La pr√©cision repr√©sente le **pourcentage de titres pour lesquels le mod√®le a correctement pr√©dit le groupe**.  
            Dans notre cas, cela signifie que le mod√®le trouve le bon groupe dans environ **{score:.0%} des cas**._

            > Exemple : si un nouveau ticket parle de "wifi qui se d√©connecte souvent", le mod√®le va analyser les mots cl√©s du titre  
            et le **classer automatiquement dans le groupe associ√© aux probl√®mes de r√©seau ou de connexion**.
            
            """)

            # Matrice de confusion avec taille r√©duite
            fig_cm, ax_cm = plt.subplots(figsize=(4, 3))  # plus petit que d√©faut
            sns.heatmap(matrice, annot=True, fmt="d", cmap="Blues", ax=ax_cm)
            ax_cm.set_title("Matrice de confusion")
            st.pyplot(fig_cm)

            st.markdown("""
            _üëâ La matrice de confusion montre comment les pr√©dictions du mod√®le sont r√©parties :_
            - Les **cases sur la diagonale** montrent les bonnes pr√©dictions (o√π le mod√®le a vu juste)
            - Les **autres cases** montrent les erreurs (ex. : titres du groupe 1 class√©s √† tort comme groupe 2)

            Cela permet de savoir **quels groupes sont parfois confondus**, ce qui peut aider √† am√©liorer le mod√®le ou √† ajuster les groupes.
            """)


            st.markdown("### üß† Th√®mes latents d√©tect√©s (LDA)")
            st.markdown("""
            LDA (Latent Dirichlet Allocation) est un mod√®le qui **d√©tecte automatiquement les grands sujets pr√©sents dans les titres**, en regroupant des mots qui apparaissent souvent ensemble.

            C‚Äôest une fa√ßon de voir quels sont les **sujets implicites** qui reviennent le plus dans les tickets, sans avoir besoin de les d√©finir √† l'avance.
            """)

            themes = appliquer_lda(X, vectoriseur)
            for i, mots in enumerate(themes):
                st.markdown(f"**Th√®me {i+1}** : {', '.join(mots)}")
                #st.markdown(f"_Ce th√®me semble concerner : {' et '.join(mots[:2])}..._")

            st.info("""
            üí° LDA est particuli√®rement utile quand on a un grand volume de titres,  
            et que qu'on souhaite **identifier automatiquement les sujets r√©currents**,  
            m√™me sans classer chaque ticket individuellement.
            """)

           # üìå R√©sum√© automatique enrichi
            st.markdown("### üßæ R√©sum√© automatique des observations")

            # Stats compl√©mentaires
            nb_groupes = donnees_valides["Groupe de titres"].nunique()
            groupe_majoritaire = donnees_valides["Groupe de titres"].value_counts().idxmax()
            nb_total = len(donnees_valides)
            nb_dominant = donnees_valides["Groupe de titres"].value_counts().max()
            part_dominant = (nb_dominant / nb_total) * 100
            top_themes = [", ".join(t[:3]) for t in themes[:3]]

            # Mots fr√©quents globaux
            mots_cles_principaux = [mot for mots in mots_par_groupe for mot in mots]
            mots_resumables = pd.Series(mots_cles_principaux).value_counts().head(5).index.tolist()

            resume_intro = f"""
            Parmi les **{nb_total} titres analys√©s**, le syst√®me a identifi√© **{nb_groupes} groupes th√©matiques distincts**.
            - Les mots les plus fr√©quents sont : **{'**, **'.join(mots_resumables)}**
            - Le **groupe dominant est le groupe {groupe_majoritaire}**, repr√©sentant **{part_dominant:.1f}%** des titres
            """

            # Diversit√©
            if pourcentage >= 70:
                resume_diversite = "üü¢ Les titres sont bien r√©partis entre les groupes, indiquant une **bonne diversit√© th√©matique**."
            elif 40 <= pourcentage < 70:
                resume_diversite = "üü† Les titres sont partiellement concentr√©s : **certains th√®mes dominent l√©g√®rement**."
            else:
                mots_dominants = mots_par_groupe[groupe_majoritaire][:5]
                resume_diversite = f"üî¥ La majorit√© des titres se concentrent sur un **seul th√®me**, associ√© √† : **{'**, **'.join(mots_dominants)}**."

            # Pr√©diction automatique
            resume_model = f"ü§ñ Le mod√®le de machine learning atteint une **pr√©cision de {score:.0%}**, ce qui le rend fiable pour classer automatiquement de nouveaux tickets."

            # LDA
            resume_lda = f"""
            üìö L‚Äôanalyse LDA a mis en √©vidence les th√®mes latents suivants :
            - **Th√®me 1** : {top_themes[0]}
            - **Th√®me 2** : {top_themes[1]}
            - **Th√®me 3** : {top_themes[2]}
            """

            # Affichage global
            st.success(f"{resume_intro}\n\n{resume_diversite}\n\n{resume_model}\n\n{resume_lda}")



        else:
            st.warning("Colonne 'Titre' absente du fichier.")

        
        st.markdown("---")
        st.markdown(f"""
            <div style="text-align:center;padding:20px;background-color:#2c3e50;color:white;border-radius:10px;">
                <p>¬© 2025 ‚Äì Tableau de Bord GLPI ‚Äì D√©velopp√© avec Streamlit</p>
                <p style="font-size:0.8em;">Derni√®re mise √† jour¬†: {datetime.now().strftime("%d/%m/%Y %H:%M")}</p>
            </div>
        """, unsafe_allow_html=True)
    
    except Exception as erreur:
        st.error(f"‚ùå Erreur lors du chargement des donn√©es¬†: {erreur}")
else:
    st.info("‚ÑπÔ∏è Veuillez importer un fichier CSV ou Excel depuis GLPI pour d√©marrer.")
    #‚ö†Ô∏è
    #st.markdown("""
    #<div style="padding:20px;background-color:#f4f6ff;border-radius:10px;border-left:5px solid #c9ba2e;">
    #    <h4 style="margin-top:0;">Comment utiliser ce tableau de bord :</h4>
    #    <ol>
    #       <li>Exportez vos donn√©es depuis GLPI (format CSV ou Excel).</li>
    #        <li>Choisissez ou glissez-d√©posez votre fichier ci‚Äëdessous.</li>
    #        <li>Explorez les visualisations et analyses propos√©es.</li>
    #        <li>Affinez votre s√©lection via les filtres lat√©raux.</li>
    #    </ol>
    #</div>
    #""", unsafe_allow_html=True)


